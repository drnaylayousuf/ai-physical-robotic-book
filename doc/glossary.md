---
id: glossary
title: Glossary of Terms
sidebar_label: Glossary
---

# Glossary of Terms

This glossary provides definitions for key terms used throughout the "Physical AI & Humanoid Robotics" book.

## A

**Action (ROS 2):** An asynchronous task with feedback, goal, and result. Used for long-running operations like navigation or manipulation.

**Anthropomorphism:** The attribution of human characteristics or behavior to non-human entities, particularly relevant in humanoid robot design.

**API (Application Programming Interface):** A set of rules and protocols for building and interacting with software applications.

**Artificial General Intelligence (AGI):** Hypothetical AI that demonstrates human-level intelligence across all cognitive tasks.

## B

**Behavior Tree:** A hierarchical structure used in robotics and AI to organize and execute complex behaviors.

**Bipedal Locomotion:** The act of walking on two legs, a key challenge in humanoid robotics.

**Bounding Box:** A rectangular frame used in computer vision to define the location of an object in an image.

## C

**Cloud Robotics:** The use of cloud computing to enhance robotic capabilities, including processing power, storage, and AI services.

**Computer Vision:** A field of AI focused on enabling computers to interpret and understand visual information from the world.

**Convolutional Neural Network (CNN):** A class of deep neural networks commonly used in computer vision applications.

**Cognitive Robotics:** A field combining robotics with cognitive science to create robots with human-like intelligence.

## D

**Deep Learning:** A subset of machine learning based on artificial neural networks with multiple layers.

**Deep Neural Network (DNN):** A neural network with multiple hidden layers between input and output layers.

**Distributed AI:** AI systems that operate across multiple devices or locations, coordinating to achieve common goals.

**Dynamic Balance:** The ability to maintain balance while moving, crucial for humanoid robots.

## E

**Edge AI:** Artificial intelligence processing performed locally on edge devices rather than in the cloud.

**Embodied AI:** AI systems that interact with and learn from the physical world through robotic bodies.

**Encoder:** A sensor that measures the position or speed of a rotating shaft, commonly used in robot joints.

**End-Effector:** The tool or device at the end of a robotic arm that interacts with the environment.

## F

**Field-Programmable Gate Array (FPGA):** A type of integrated circuit that can be programmed after manufacturing for specific applications.

**Forward Kinematics:** The process of calculating the position and orientation of a robot's end-effector based on joint angles.

**Fused Deposition Modeling (FDM):** A 3D printing technology that uses a heated nozzle to extrude thermoplastic material.

## G

**Gaussian Mixture Model (GMM):** A probabilistic model used for representing normally distributed subpopulations within an overall population.

**General Artificial Intelligence (GAI):** See Artificial General Intelligence.

**Generative Pre-trained Transformer (GPT):** A class of large language models developed by OpenAI.

**Glossary:** A list of terms with their definitions, typically found at the end of a book or document.

**GPU (Graphics Processing Unit):** A specialized electronic circuit designed to rapidly manipulate and alter memory to accelerate the creation of images in a frame buffer intended for output to a display device.

## H

**Hidden Markov Model (HMM):** A statistical model where the system being modeled is assumed to be a Markov process with unobserved (hidden) states.

**Human-Robot Interaction (HRI):** The study of interactions between humans and robots.

**Humanoid Robot:** A robot with a human-like body structure, typically having a head, torso, two arms, and two legs.

## I

**Inertial Measurement Unit (IMU):** An electronic device that measures and reports a body's specific force, angular rate, and sometimes the magnetic field surrounding the body.

**Inverse Kinematics:** The process of determining joint angles required to place a robot's end-effector at a desired position and orientation.

**Isaac Sim:** NVIDIA's robotics simulation environment built on the Omniverse platform.

**Isaac ROS:** NVIDIA's hardware-accelerated packages for ROS 2.

## J

**Joint:** A connection between two links in a robot that allows relative motion.

**JSON (JavaScript Object Notation):** A lightweight data-interchange format that is easy for humans to read and write and easy for machines to parse and generate.

## K

**Kinematics:** The branch of mechanics concerned with the motion of objects without reference to force or mass.

**Knowledge Graph:** A structured representation of knowledge that describes relationships between entities.

## L

**Large Language Model (LLM):** A language model with many parameters that is trained on vast amounts of text data.

**Latency:** The time delay between a stimulus and response, critical in real-time robotic systems.

**LIDAR (Light Detection and Ranging):** A remote sensing method that uses light in the form of a pulsed laser to measure distances.

**Locomotion:** The ability to move from one place to another, particularly relevant for mobile robots.

**Long Short-Term Memory (LSTM):** A type of recurrent neural network designed to learn from experience over long periods.

## M

**Machine Learning (ML):** A subset of AI that enables systems to learn and improve from experience without being explicitly programmed.

**Manipulation:** The ability of a robot to physically interact with objects in its environment.

**Markov Decision Process (MDP):** A mathematical framework for modeling decision-making in situations where outcomes are partly random and partly under the control of a decision maker.

**Middleware:** Software that provides common services and capabilities to applications beyond what's offered by the operating system.

**Mobile Robot:** A robot that can move around in its environment using actuated mechanisms.

**Motion Planning:** The process of determining how to move from one location to another while avoiding obstacles.

**MoveIt!:** A state-of-the-art motion planning framework for ROS.

## N

**Named Entity Recognition (NER):** A subtask of information extraction that seeks to locate and classify named entities in text into predefined categories.

**Natural Language Processing (NLP):** A field of AI focused on the interaction between computers and humans through natural language.

**Navigation2:** The ROS 2 navigation stack for mobile robot navigation.

**Neural Network:** A computing system inspired by the biological neural networks that constitute animal brains.

**Node (ROS 2):** A process that performs computation in ROS 2.

## O

**Object Detection:** A computer vision technique that identifies and locates objects within an image or video.

**Omniverse:** NVIDIA's platform for 3D design collaboration and world simulation.

**OpenAI:** An artificial intelligence company focused on developing and applying safe artificial general intelligence.

**OpenCV:** An open-source computer vision and machine learning software library.

**Oversampling:** A technique used in signal processing to improve resolution and reduce aliasing.

## P

**Path Planning:** The process of determining a route from a start location to a goal location.

**Perception:** The ability of a robot to interpret sensory information from its environment.

**Physical AI:** A field combining artificial intelligence with physical systems, enabling robots to understand and interact with the physical world.

**Point Cloud:** A set of data points in space, typically representing the external surfaces of objects.

**Proportional-Integral-Derivative (PID) Controller:** A control loop feedback mechanism widely used in industrial control systems.

**Psychomotor:** Relating to the connection between cognitive function and physical movement.

## Q

**Quality of Service (QoS):** A feature in ROS 2 that allows publishers and subscribers to specify how data should be handled in terms of reliability, durability, and other parameters.

**Quaternion:** A mathematical concept used to represent rotations in 3D space, avoiding issues like gimbal lock.

## R

**Recurrent Neural Network (RNN):** A class of neural networks where connections between nodes form a directed graph along a temporal sequence.

**Reinforcement Learning:** A type of machine learning where an agent learns to make decisions by performing actions and receiving rewards or penalties.

**Robot Operating System 2 (ROS 2):** A flexible framework for writing robot software, successor to ROS.

**Robotics Middleware:** Software that provides common services and capabilities to robot applications.

**ROS (Robot Operating System):** A flexible framework for writing robot software (now ROS 1, succeeded by ROS 2).

**Rigid Body:** An idealization of a solid body in which deformation is neglected.

**RRT (Rapidly-exploring Random Tree):** A path planning algorithm that builds a space-filling tree to find paths in high-dimensional spaces.

## S

**Sensor Fusion:** The process of combining data from multiple sensors to achieve better accuracy and reliability than could be achieved by using a single sensor.

**Service (ROS 2):** A synchronous request-response communication pattern in ROS 2.

**SLAM (Simultaneous Localization and Mapping):** The computational problem of constructing or updating a map of an unknown environment while simultaneously keeping track of an agent's location within it.

**Speech Recognition:** The ability of a machine to identify words and phrases in spoken language and convert them to text.

**State Machine:** A computational model used to design computer programs or logic circuits that can be in exactly one of a finite number of states at any given time.

**Subsumption Architecture:** A behavior-based approach to robotics that decomposes complex behaviors into simple, independent behaviors.

## T

**Tensor Processing Unit (TPU):** An AI accelerator application-specific integrated circuit developed by Google for neural network machine learning.

**TensorRT:** NVIDIA's inference optimizer and runtime for deep learning models.

**Topic (ROS 2):** A publish-subscribe communication pattern in ROS 2.

**Transformer Model:** A deep learning model that uses attention mechanisms to weigh the importance of input data.

**Trajectory:** The path that a moving object follows through space as a function of time.

**Trust Region:** A term used in mathematical optimization to denote the subset of the domain of the approximating model used for the next iterate.

## U

**Unified Robot Description Format (URDF):** An XML format for representing a robot model, used in ROS.

**Universal Scene Description (USD):** A 3D scene description and file format developed by Pixar.

**Unstructured Environment:** An environment that is not specifically designed or modified for robot operation.

## V

**Variable Impedance Control:** A control strategy that allows robots to adjust their mechanical impedance to better interact with their environment.

**Vision-Language-Action (VLA):** A field combining computer vision, natural language processing, and robot action for integrated physical AI systems.

**Virtual Reality (VR):** A simulated experience that can be similar to or completely different from the real world.

## W

**Whole-Body Control:** A control approach that considers the entire robot body when planning and executing movements.

**Whisper:** OpenAI's automatic speech recognition system.

**Workspace:** The space within which a robot can operate.

## X

**XACRO:** An XML macro language that allows you to use variables, mathematical expressions, and macros to write more concise and readable robot descriptions in URDF.

## Y

**YOLO (You Only Look Once):** A real-time object detection system.

## Z

**Zero Moment Point (ZMP):** A concept used in robotics and biomechanics to propose a stability criterion for bipedal robots.

**ZMP (Zero Moment Point):** See Zero Moment Point.

---

*This glossary will continue to be updated as new terms are introduced throughout the book.*